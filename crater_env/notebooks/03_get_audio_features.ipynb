{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7b86ae-35af-4978-94be-416ffa19e2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/qnfbs7f539d_d_vxqj6lwsdr0000gn/T/ipykernel_41713/4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92a2eb6-6952-4873-ba8d-d205e99a1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec1c03a-da05-467f-846a-75a47ff38a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIPY_CLIENT_ID= 'a5d9928d7d874cebafc8a8a632277854'\n",
    "SPOTIPY_CLIENT_SECRET= 'a3341b047daa4007a5bc3ad2fc9413c7'\n",
    "SPOTIPY_REDIRECT_URI = 'http://127.0.0.1:9090'\n",
    "SCOPE = 'user-top-read user-library-read playlist-modify-public'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b6d233-a4d6-426b-baef-f3a9f803f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_manager=SpotifyOAuth(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET, redirect_uri=SPOTIPY_REDIRECT_URI, scope=SCOPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfcadec1-e218-4dcc-a914-dc49f3aa1df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/qnfbs7f539d_d_vxqj6lwsdr0000gn/T/ipykernel_41713/1840087059.py:1: DeprecationWarning: You're using 'as_dict = True'.get_access_token will return the token string directly in future versions. Please adjust your code accordingly, or use get_cached_token instead.\n",
      "  token = auth_manager.get_access_token()['access_token']\n"
     ]
    }
   ],
   "source": [
    "token = auth_manager.get_access_token()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b45492-57d1-46e2-a490-8dac2842da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/tracks_vibes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a10f021d-6a09-4bed-b6e4-71dbaba872b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_audio_features(track_ids, access_token):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    track_data = []\n",
    "\n",
    "    # Retrieve audio features in batches of 100\n",
    "    count = 1\n",
    "    for i in range(0, len(track_ids), 100):\n",
    "        print(count)\n",
    "        count+=1\n",
    "        batch_track_ids = track_ids[i:i+100]\n",
    "        audio_features_url = f'https://api.spotify.com/v1/audio-features/?ids={\",\".join(batch_track_ids)}'\n",
    "        response = requests.get(audio_features_url, headers=headers)\n",
    "\n",
    "        # Check if the response was successful\n",
    "        if response.status_code == 200:\n",
    "            audio_features_data = response.json()\n",
    "            if 'audio_features' in audio_features_data:\n",
    "                audio_features = audio_features_data['audio_features']\n",
    "                # Add track information and audio features to the data frame\n",
    "                for features in audio_features:\n",
    "                    if features:\n",
    "                        track_info = {\n",
    "                            'track_id': features['id'],\n",
    "                            'Danceability': features['danceability'],\n",
    "                            'Energy': features['energy'],\n",
    "                            'Loudness': features['loudness'],\n",
    "                            'Speechiness': features['speechiness'],\n",
    "                            'Acousticness': features['acousticness'],\n",
    "                            'Instrumentalness': features['instrumentalness'],\n",
    "                            'Liveness': features['liveness'],\n",
    "                            'Valence': features['valence'],\n",
    "                            'Tempo': features['tempo'],\n",
    "                            'Duration_ms': features['duration_ms'],\n",
    "                            'Time_Signature': features['time_signature']\n",
    "                        }\n",
    "                        track_data.append(track_info)\n",
    "            else:\n",
    "                print(\"The 'audio_features' key was not found in the response.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch audio features. Status code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "    return pd.DataFrame(track_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "748592b6-8849-405a-aa1d-dc743d674415",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n"
     ]
    }
   ],
   "source": [
    "track_ids = df['track_id'].tolist()\n",
    "\n",
    "# Get audio features DataFrame\n",
    "audio_features_df = get_audio_features(track_ids, token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783ab4e8-48d3-42e2-8ed0-4be86408d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the audio features back into the original DataFrame on 'track_id'\n",
    "merged_df = pd.merge(df, audio_features_df, on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53a85fa3-3b40-4215-a347-5dc9a5cc6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bb969b4-ea2f-4b0a-9eff-70fbc6e7b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_info(artist_ids, access_token):\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    artist_data = []\n",
    "\n",
    "    # Retrieve artist details in batches of 50\n",
    "    for i in range(0, len(artist_ids), 50):\n",
    "        batch_artist_ids = artist_ids[i:i+50]\n",
    "        artists_url = f'https://api.spotify.com/v1/artists?ids={\",\".join(batch_artist_ids)}'\n",
    "        response = requests.get(artists_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            artists_response = response.json()\n",
    "            if 'artists' in artists_response:\n",
    "                artists = artists_response['artists']\n",
    "                for artist in artists:\n",
    "                    if artist:  # Ensure artist is not None\n",
    "                        artist_info = {\n",
    "                            'Artist ID': artist['id'],\n",
    "                            'Artist Followers': artist['followers']['total'],\n",
    "                            'Artist Genres': ', '.join(artist['genres']),\n",
    "                            'Artist Popularity': artist['popularity']\n",
    "                        }\n",
    "                        artist_data.append(artist_info)\n",
    "            else:\n",
    "                print(\"The 'artists' key was not found in the response.\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch artist details. Status code: {response.status_code}, Response: {response.text}\")\n",
    "    \n",
    "    return pd.DataFrame(artist_data)\n",
    "\n",
    "def fetch_artist_ids_and_mapping_from_tracks(track_ids, access_token):\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    artist_ids = set()\n",
    "    track_artist_mapping = []\n",
    "\n",
    "    for i in range(0, len(track_ids), 50):\n",
    "        batch_track_ids = track_ids[i:i+50]\n",
    "        tracks_url = f'https://api.spotify.com/v1/tracks?ids={\",\".join(batch_track_ids)}'\n",
    "        response = requests.get(tracks_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            tracks_data = response.json()['tracks']\n",
    "            for track in tracks_data:\n",
    "                if track:  # Ensure track is not None\n",
    "                    for artist in track['artists']:\n",
    "                        artist_ids.add(artist['id'])\n",
    "                        track_artist_mapping.append({'track_id': track['id'], 'Artist ID': artist['id']})\n",
    "        else:\n",
    "            print(f\"Failed to fetch track details for batch. Status code: {response.status_code}, Response: {response.text}\")\n",
    "    \n",
    "    return list(artist_ids), pd.DataFrame(track_artist_mapping)\n",
    "\n",
    "def get_artist_info_and_merge(df, access_token):\n",
    "    track_ids = df['track_id'].unique().tolist()\n",
    "    artist_ids, track_artist_mapping_df = fetch_artist_ids_and_mapping_from_tracks(track_ids, access_token)\n",
    "    \n",
    "    # Fetch artist details\n",
    "    artist_df = get_artist_info(artist_ids, access_token)\n",
    "    \n",
    "    # Merge the track_artist_mapping_df with artist_df to include artist details\n",
    "    detailed_track_artist_df = pd.merge(track_artist_mapping_df, artist_df, on='Artist ID', how='left')\n",
    "    \n",
    "    # Merge this detailed artist information back into the original DataFrame\n",
    "    # This assumes your original DataFrame has a 'track_id' column to merge on\n",
    "    merged_df = pd.merge(df, detailed_track_artist_df, on='track_id', how='left')\n",
    "    \n",
    "    return merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e12ca18-ebc9-452e-866e-c98b83afa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio_artists = get_artist_info_and_merge(merged_df,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d871694-aab4-4290-9486-bf16fae13760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audio_artists_clean = df_audio_artists.drop_duplicates(subset = ['search_id','track_id']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd262dde-2034-46e1-ac3d-73175a077700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_audio_artists_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f251ba9a-4f2a-49ef-8cd6-6205801d3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Split 'Artist Genres' into a list of genres\n",
    "df['Artist Genres'] = df['Artist Genres'].str.split(', ').apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform 'Artist Genres' into a binary matrix\n",
    "genres_matrix = mlb.fit_transform(df['Artist Genres'])\n",
    "\n",
    "# Create a sparse DataFrame with one column for each genre\n",
    "sparse_genres_df = pd.DataFrame(genres_matrix, columns=mlb.classes_)\n",
    "\n",
    "# Adding the 'search_id' or 'track_id' to the sparse dataframe for later merging\n",
    "sparse_genres_df['track_id'] = df['track_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c4a2d82-504a-4afc-b0b7-65ed321c6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA to reduce dimensionality to 5 principal components\n",
    "pca = PCA(n_components=5)\n",
    "reduced_data = pca.fit_transform(sparse_genres_df.drop('track_id', axis=1))\n",
    "\n",
    "# Creating a DataFrame for the PCA-reduced data\n",
    "pca_genres_df = pd.DataFrame(reduced_data, columns=[f'PC{i+1}' for i in range(5)])\n",
    "\n",
    "# Adding the 'track_id' back to the PCA-reduced DataFrame for identification\n",
    "pca_genres_df['track_id'] = df['track_id']\n",
    "\n",
    "# If you need to merge this back with the original DataFrame\n",
    "# This will add the PCA components as new columns in your original DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1de885e-218e-4b88-9412-11b70cceef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, pca_genres_df, on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7b9cc7d-9fd4-4d44-842c-22b75458b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_merged.drop_duplicates(subset = ['search_id','track_id']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d015c22-e4a4-49f5-a5e8-0afaa4260889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('assets/df_pca.csv' ,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91bfb2-cc74-4d12-a4ea-8dbcf7240658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crater Kernel",
   "language": "python",
   "name": "crater_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
